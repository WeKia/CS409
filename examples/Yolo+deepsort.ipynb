{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/ubuntu/project')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import cv2, mmcv\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from utils.get_utube import get_youtube\n",
    "from utils.display import video_display\n",
    "from detectors import DSFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = ['480p']\n",
    "\n",
    "videos = get_youtube(\"https://www.youtube.com/watch?v=eoligIhaKkw\", res, use_cache=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(paths):\n",
    "    videos = []\n",
    "    for path in paths:\n",
    "        video = mmcv.VideoReader(path)\n",
    "        frames = [cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) for frame in video]\n",
    "\n",
    "        videos.append(frames)\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['../tmp/MOT16-01-raw.webm', '../tmp/MOT16-09-raw.webm']\n",
    "res = ['MOT16-01', 'MOT16-09']\n",
    "\n",
    "videos = get_videos(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyxy_to_xywh(boxes, width, height):\n",
    "    xywh_boxes = []\n",
    "    \n",
    "    for box in boxes:\n",
    "        x1 = int(box[0] * width)\n",
    "        y1 = int(box[1] * height)\n",
    "        x2 = int(box[2] * width)\n",
    "        y2 = int(box[3] * height)\n",
    "                \n",
    "        w = abs(x2 - x1)\n",
    "        h = abs(y2 - y1)\n",
    "        x = x1 + w/2\n",
    "        y = y1 + h/2\n",
    "        \n",
    "        xywh_boxes.append([x, y, w, h])\n",
    "    \n",
    "    return np.array(xywh_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480p tracked in 70.2793398060021\n"
     ]
    }
   ],
   "source": [
    "from yolo.models import Yolov4\n",
    "from yolo.tool.utils import plot_boxes_cv2\n",
    "from yolo.tool.torch_utils import do_detect\n",
    "from deepsort.deep_sort import DeepSort\n",
    "\n",
    "temp_folder = '../tmp/'\n",
    "weight_file = '../yolo/weight/yolov4.pth'\n",
    "sort_weight = '../deepsort/deep/checkpoint/ckpt.t7'\n",
    "class_names = ['person']\n",
    "\n",
    "model = Yolov4(inference=True)\n",
    "pretrained_dict = torch.load(weight_file, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(pretrained_dict)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "deepsort = DeepSort(model_path=sort_weight, nms_max_overlap=0.5, use_cuda=True)\n",
    "\n",
    "width = 416\n",
    "height = 416\n",
    "\n",
    "colors = np.array([[1, 0, 1], [0, 0, 1], [0, 1, 1], [0, 1, 0], [1, 1, 0], [1, 0, 0]], dtype=np.float32)\n",
    "\n",
    "def get_color(c, x, max_val):\n",
    "        ratio = float(x) / max_val * 5\n",
    "        i = int(math.floor(ratio))\n",
    "        j = int(math.ceil(ratio))\n",
    "        ratio = ratio - i\n",
    "        r = (1 - ratio) * colors[i][c] + ratio * colors[j][c]\n",
    "        return int(r * 255)\n",
    "\n",
    "for j, r in enumerate(res):\n",
    "    frames = videos[j]\n",
    "    \n",
    "    frames_tracked = []\n",
    "    \n",
    "    start = time.monotonic()\n",
    "    \n",
    "    for i, frame in enumerate(frames):\n",
    "        print('Tracking frame: {} res : {}'.format(i + 1, r), end='\\r')\n",
    "        \n",
    "        H, W, _ = frame.shape\n",
    "        \n",
    "        sized = cv2.resize(frame, (width, height))\n",
    "\n",
    "        # Detect faces\n",
    "        boxes = np.array(do_detect(model, sized, 0.4, 0.6, True)[0])\n",
    "        \n",
    "        outputs = []\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            bbox, cls_conf, cls_ids = boxes[:, 0:4], boxes[:, 5], boxes[:, 6]\n",
    "\n",
    "            # Select boxes class 0 (person)\n",
    "            mask = cls_ids == 0\n",
    "            \n",
    "            # Do tracking if only person detected\n",
    "            if np.any(mask):\n",
    "                bbox = bbox[mask]\n",
    "                cls_conf = cls_conf[mask]\n",
    "\n",
    "                bbox = xyxy_to_xywh(bbox, width, height)\n",
    "\n",
    "                outputs = deepsort.update(bbox, cls_conf, sized)\n",
    "\n",
    "\n",
    "        # Draw faces\n",
    "        frame_draw = sized.copy()\n",
    "        if len(outputs) > 0:\n",
    "            for box in outputs:\n",
    "                x1 = int(box[0])\n",
    "                y1 = int(box[1])\n",
    "                x2 = int(box[2])\n",
    "                y2 = int(box[3])\n",
    "                \n",
    "                identity = box[-1]\n",
    "                \n",
    "                offset = identity * 123457 % 80\n",
    "                red = get_color(2, offset, 80)\n",
    "                green = get_color(1, offset, 80)\n",
    "                blue = get_color(0, offset, 80)\n",
    "                \n",
    "                rgb = (red, green, blue)\n",
    "                \n",
    "                frame_draw = cv2.putText(frame_draw, f'person_{identity}', (x1 - 10, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,0.5, rgb, 2)\n",
    "                frame_draw = cv2.rectangle(frame_draw, (x1, y1), (x2, y2), rgb, 1)\n",
    "\n",
    "        # Add to frame list\n",
    "        frames_tracked.append(cv2.resize(frame_draw, (W, H)))\n",
    "    \n",
    "    print(f'{r} tracked in {time.monotonic() - start}')\n",
    "\n",
    "    H, W, _ = frames_tracked[0].shape\n",
    "    \n",
    "    dim = (W, H)\n",
    "\n",
    "    # Use vp9 codec and webm format to show video in notebook\n",
    "    # TODO : Why opencv doesn't support h264? -> how can we show video in format mp4\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'VP90')   \n",
    "    video_tracked = cv2.VideoWriter(temp_folder + f'video_tracked_{r}.webm', fourcc, 20.0, dim)\n",
    "    for frame in frames_tracked:\n",
    "        video_tracked.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    video_tracked.release()\n",
    "    \n",
    "    # Use vp9 codec and webm format to show video in notebook\n",
    "    # TODO : Why opencv doesn't support h264? -> how can we show video in format mp4\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')   \n",
    "    video_tracked = cv2.VideoWriter(temp_folder + f'video_tracked_{r}.mp4', fourcc, 20.0, dim)\n",
    "    for frame in frames_tracked:\n",
    "        video_tracked.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    video_tracked.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_display(temp_folder + 'video_tracked_480p.webm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
